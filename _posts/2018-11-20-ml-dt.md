---
layout: post
title: "DT数学原理与python实现"
subtitle: 'The Mathematical Principles and Python Implementation of DT'
author: "Quanli"
header-style: text
catalog: true
mathjax: true
tags:
  - machine learning
  - decision tree
---

Decision Tree(DT)主要包括：
* 特征选择
* 决策树的生成
* 决策树的修建

## 特征选择
特征选择主要通过特征给模型带来的信息增益，特征信息增益越大表名该特征越重要。

### 信息熵
在信息论与概率统计中，熵是表示随机变量不确定性的度量。

设$X$是一个有限个值的离散随机变，其概率分布为：

$$
P(X=x_i)=p_i, \quad i=1,2, \cdots ,n
$$

则随机变量$X$的熵定义为：

$$
H(X)=- \sum_{i=1}^N p_ilogp_i
$$

熵越大，随机变量的不确定性越大，其中：

$$
0\leq H(p) \leq logn
$$

#### 条件熵
设随机变量$(X,Y)$，其联合概率分布为：

$$
P(X=x_i, Y=y_j)=p_{ij}, \quad i=1,2, \cdots ,n; \quad j=1,2, \cdots ,m
$$

条件熵$H(Y|X)$表示在已知随机变量$X$的条件下随机变量$Y$的不确定性。

---
